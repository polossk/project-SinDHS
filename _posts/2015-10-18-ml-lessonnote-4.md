---
layout: post
title: "[ML] 机器学习课程 笔记本 (4) 杂"
date: 2015-10-18 23:04:00 +0800
categories: 笔记本 机器学习
tags: machinelearning
---
到今天晚上为止，为期四天的培训终于结束了。学到很多，感触也很多，当然更多的是对过往知识更深一层的理解。也是第一次切身的意识到了大数据的紧迫感和数据处理当中计算思维的美妙。今天最后一节课是实战课，实际上并没有怎么施展出什么有趣的东西，当然收获也是有的，比如万恶的文件编码，当然还有一点就是，可惜Sciruby不做了，要不然我肯定不用python这个需要带游标卡尺看书的语言。

表完ruby黑完python之后还是写写这几天剩下的有趣的东西吧

## 特征选择中k值确定与测试集和训练集

之前在第一篇笔记中提到，特征的选取必须抓住不变量。然而最终结果还是需要筛选出k个有用的特征，这里就有一个重要的问题，k值如何确定。

老师讲到了两种方法，交叉验证法和做出分类结果和k值取值变化的结果。后者更容易直观的看出如何设置，前者则是一个普遍的思路，因为事实上可以得知训练集对于结果的影响只有当训练集无穷大的时候才可以完全忽略不计，但是显然这个是不可能的。交叉验证法的主要操作在于，事先将整个已经准备好的标记数据分成k份，选取其中一份作为测试集，其他为训练集。训练一次之后，用测试集做测试，然后换测试集，重复直至所有的k份数据都用做过测试集为止。随后将这些结果做平均，并评价此时的特征选择当中的k值选取。

个人感觉这个方法除了太累以外，还是可以接受的，其实也不算太累，只要事先准备好了标记好的数据和核心实现的文件，外部写一个脚本调用就好了。但是换言之对人的要求比较高，但是比较实用且有效。

另外一点就是，如果模型中的某些参数也不好确定，同样可以利用交叉验证法进行处理，只不过此时对应的是把训练集进行拆分罢了。

顺手把老师后来的补充直接贴出来好了。

> 关于交叉验证的问题
> 
> (1) 定义： 将整个带标记分类数据集分成k份，每次取其中k-1份训练，剩余1份
> 测试，如此循环k次。这种做法叫做k-折交叉验证或者测试。每次循环会得到在测
> 试集上的评价指标，通常会将这些指标平均报告出来
> 
> (2) 参数确定：有些分类器需要在训练中确定参数，比如kNN中的k、SVM中的系数
> C等等。可以采用上述k-折交叉验证的思路来确定这些参数。做法是将训练集分成
> s份，其中s-1份用作训练，其余1份用作验证(其次也是测试)，使得s-折交叉验证
> 平均指标最高的参数值即为最后真正训练所选的参数值。
> 
> (3) 问题1：k-折交叉测试后最终用的模型到底是哪个？ 答：k-折交叉测试不是
> 为了得到最终用的模型，而是反映分类器的平均效果。
> 
> (4) 问题2：如果外层用k-折交叉测试报告分类器结果，内层用s-折交叉测试确定
> 最优参数，那么确定参数之后到底选哪个模型？ 答：我的理解是得到最优参数
> 后，在整个训练集合上重新训练模型。即内层s-折只是为了得到最优参数，外层
> k-折才报告结果。

## 二类问题和多类问题

二类问题的解决方案里，有的可以直接上手解决多类分类问题，有的则不行。直观的想法是把多类问题转换成二类问题的某种组合来进行解决，所以就有了1-V-R和1-V-1两种方案。

不妨假设现在需要分成四类A, B, C, D，1-V-R的思路其实就是认为，A和非A应当用一个分类器s1进行处理，同样的B和非B也应当用另一个独立的分类器s2处理，所以就有四个独立的二类分类器来处理这个问题。一般的讲，如果有N个类需要分类，这个方法只需要训练独立的N的分类器即可。但是问题也是比较明显的，比如训练集的不均衡问题，A类假设有100个样本，那BCD的总和到底应该怎么控制呢？当然具体参数需要具体分析。

另一种思路就是，A和B应当是不同类，那么同理，任意两个不同类的都应当有一个独立的分类器来进行处理。也就是说，如果有N个类需要分类，这个方法需要训练$$\binom{N}{2}$$个分类器来进行处理。当然这个是有利有弊的，首先这个完全避免了训练集的不均衡问题，但是同样的这个方法付出了大量的训练成本。

所以还是具体问题具体分析更好。

## 贴标签问题

举一个多类问题的简单应用，就是贴标签的问题。假设一篇文章可以被贴上不同类别的至多x个标签，应该怎么做？

一个直观的想法是直接去和每一个类A，类B等等判断距离，然后把前x个都贴上。

当然并不能说这个方法就一定是错的，你只要加上一个threshold就行了，把太离谱的答案扔掉，我个人感觉这个方法的结果至少不会太差。

还有一种方法就是利用分类器A和所有非A，B和所有非B，等等去进行判断，然后再输出结果。这个的结果就比较保守了，所以容错率也更高。

## 众包

这个词其实是我在学生物信息学的时候就第一次看到了，当初讲解道蛋白质的氨基酸序列和结构的时候就有一个很出名的例子。

简单地说就是，我现在知道空间构成的规则，但是这么多种构成的可能，怎么样才能找到呢。

结果这个研究员，就找到了他的计算机基友，希望让他帮他解决问题。

但是这个计算机的基友很有趣，他直接写了一个游戏，Foldit，整理他！发布，然后10天之后，各路玩家就down掉了15年悬而未解的结构解析问题。因而这篇成果论文发到science上的时候，附上了一句有趣的话：

Seth Cooper, Firas Khatib, ..., and **>57,000 Foldit players**

所以，有的时候人类的力量还是不可小视的，要不然人也不会生存到现在。

## And Then What

恩，是时候洗澡睡觉了，明天早起orz。。。